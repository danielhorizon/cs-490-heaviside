{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb\n",
    "def load_data_v2(shuffle=True, batch_size=None, seed=None):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2023, 0.1994, 0.2010],\n",
    "    )\n",
    "\n",
    "    # define transforms for validation and train.\n",
    "    valid_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    # loading in dataset.\n",
    "    train_dataset = CIFAR10(train=True, download=True,\n",
    "                            root=\"../data\", transform=train_transform)\n",
    "    valid_dataset = CIFAR10(train=True, download=True,\n",
    "                            root=\"../data\", transform=valid_transform)\n",
    "    # need to transform the test according to the train.\n",
    "    test_dataset = CIFAR10(train=False, download=True,\n",
    "                           root=\"../data\", transform=train_transform)\n",
    "\n",
    "    print(\"Train Size: {}, Test Size: {}, Valid Size: {}\".format(\n",
    "        len(train_dataset), len(test_dataset), len(valid_dataset)))\n",
    "\n",
    "    # spliiting into validation/train/test.\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    valid_size = 0.10\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    print(\"Train Size:{} Valid Size: {}\".format(len(train_idx), len(valid_idx)))\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
    "        num_workers=0, pin_memory=True,\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
    "        num_workers=0, pin_memory=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=0, pin_memory=True,\n",
    "    )\n",
    "    return train_loader, valid_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Size: 50000, Test Size: 10000, Valid Size: 50000\n",
      "Train Size:45000 Valid Size: 5000\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = load_data_v2(\n",
    "            batch_size=512, shuffle=True, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, title):\n",
    "    npimg = img.numpy()\n",
    "    fig = plt.figure(figsize = (5, 15))\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sample data shape is  torch.Size([512, 3, 32, 32]) torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "sampleX,sampleY = iter(train_loader).next()\n",
    "print(\"The sample data shape is \",sampleX.shape,sampleY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "  img = img / 2 + 0.5   # unnormalize\n",
    "  npimg = img.numpy()   # convert from tensor\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "imgs, lbls = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for showing frogs\n",
    "# for i in range(100):  # show just the frogs\n",
    "#     if lbls[i] == 6:  # 6 = frog\n",
    "#         imshow(torchvision.utils.make_grid(imgs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Accuracy + F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/timeseries/adversarial'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('/app/timeseries/adversarial/models/cifar/af1.pth').to(\"cuda:3\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds, test_labels = np.array([]), np.array([])\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(test_loader):\n",
    "        labels_list = labels.cpu().numpy()\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(inputs)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        pred_arr = predicted.cpu().numpy()\n",
    "        label_arr = labels.cpu().numpy()\n",
    "\n",
    "        test_labels = np.concatenate([test_labels, label_arr])\n",
    "        test_preds = np.concatenate([test_preds, pred_arr])\n",
    "\n",
    "\n",
    "    # calculating metrics \n",
    "    test_acc = accuracy_score(y_true=test_labels, y_pred=test_preds)\n",
    "    test_f1_micro = f1_score(y_true=test_labels, y_pred=test_preds, average='micro')\n",
    "    test_f1_macro = f1_score(y_true=test_labels, y_pred=test_preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.5943\n",
      "0.5943\n",
      "0.5997470307383832\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: {}\".format(test_acc))\n",
    "print(test_f1_micro)\n",
    "print(test_f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing the L2 Adversarial Attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the paper, i.e. not exact same version of the code on https://github.com/carlini/nn_robust_attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Binary search method for c, (2) Optimization on tanh space, (3) Choosing method best l2 adversaries is NOT IN THIS CODE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of iterations to perform gradient descent \n",
    "MAX_ITERATIONS = 1000\n",
    "# larger values converge faster to less accurate results\n",
    "LEARNING_RATE = 1e-2\n",
    "# should we target one specific class? or just be wrong?\n",
    "TARGETED = False\n",
    " # how strong the adversarial example should be\n",
    "CONFIDENCE = 1e-4 \n",
    "\n",
    "\n",
    "def cw_l2_attack(model, images, labels, targeted=TARGETED, \n",
    "                 c=CONFIDENCE, kappa=0, max_iter=MAX_ITERATIONS, learning_rate=0.01) :\n",
    "\n",
    "    images = images.to(device)     \n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Define f-function\n",
    "    def f(x):\n",
    "        outputs = model(x)\n",
    "        one_hot_labels = torch.eye(len(outputs[0]))[labels].to(device)\n",
    "\n",
    "        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n",
    "        j = torch.masked_select(outputs, one_hot_labels.byte())\n",
    "        \n",
    "        # If targeted, optimize for making the other class most likely \n",
    "        if targeted :\n",
    "            return torch.clamp(i-j, min=-kappa)\n",
    "        # If untargeted, optimize for making the other class most likely \n",
    "        else :\n",
    "            return torch.clamp(j-i, min=-kappa)\n",
    "    \n",
    "    w = torch.zeros_like(images, requires_grad=True).to(device)\n",
    "    optimizer = optim.Adam([w], lr=learning_rate)\n",
    "    prev = 1e10\n",
    "    \n",
    "    for step in range(max_iter) :\n",
    "        a = 1/2*(nn.Tanh()(w) + 1)\n",
    "        loss1 = nn.MSELoss(reduction='sum')(a, images)\n",
    "        loss2 = torch.sum(c*f(a))\n",
    "\n",
    "        cost = loss1 + loss2\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Early Stop when loss does not converge.\n",
    "        if step % (max_iter//10) == 0 :\n",
    "            if cost > prev :\n",
    "                print('Attack Stopped due to CONVERGENCE....')\n",
    "                return a\n",
    "            prev = cost\n",
    "        \n",
    "        print('- Learning Progress : %2.2f %%        ' %((step+1)/max_iter*100), end='\\r')\n",
    "\n",
    "    attack_images = 1/2*(nn.Tanh()(w) + 1)\n",
    "\n",
    "    return attack_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Image & Predicted Label\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test text: 26.610000 %    \n"
     ]
    }
   ],
   "source": [
    "print(\"Attack Image & Predicted Label\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    images = cw_l2_attack(model, images, labels, targeted=False, c=0.1)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "\n",
    "    # adding the nubme of images \n",
    "    total += images.shape[0]\n",
    "    correct += (pre == labels).sum()\n",
    "        \n",
    "print('Accuracy of test text: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Size: 50000, Test Size: 10000, Valid Size: 50000\n",
      "Train Size:45000 Valid Size: 5000\n"
     ]
    }
   ],
   "source": [
    "train_loader_1, val_loader_1, test_loader_1 = load_data_v2(\n",
    "            batch_size=1, shuffle=True, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack Image & Predicted Label\n",
      "- Learning Progress : 0.10 %        \r",
      "- Learning Progress : 0.20 %        \r",
      "- Learning Progress : 0.30 %        \r",
      "- Learning Progress : 0.40 %        \r",
      "- Learning Progress : 0.50 %        \r",
      "- Learning Progress : 0.60 %        \r",
      "- Learning Progress : 0.70 %        \r",
      "- Learning Progress : 0.80 %        \r",
      "- Learning Progress : 0.90 %        \r",
      "- Learning Progress : 1.00 %        \r",
      "- Learning Progress : 1.10 %        \r",
      "- Learning Progress : 1.20 %        \r",
      "- Learning Progress : 1.30 %        \r",
      "- Learning Progress : 1.40 %        \r",
      "- Learning Progress : 1.50 %        \r",
      "- Learning Progress : 1.60 %        \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/.local/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:25.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of test text: 15.686275 %    \n"
     ]
    }
   ],
   "source": [
    "print(\"Attack Image & Predicted Label\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "i = 0 \n",
    "for images, labels in test_loader_1:\n",
    "    images = cw_l2_attack(model, images, labels, targeted=False, c=0.1)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    \n",
    "    _, pre = torch.max(outputs.data, 1)\n",
    "\n",
    "    # adding the nubme of images \n",
    "    total += images.shape[0]\n",
    "    correct += (pre == labels).sum()\n",
    "    i += 1 \n",
    "    if i > 50: \n",
    "        break\n",
    "        \n",
    "print('Accuracy of test text: %f %%' % (100 * float(correct) / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
