{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/app/timeseries/multiclass_src/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading in from eval json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "results_path = \"/app/timeseries/multiclass_src/results/new_runs\"\n",
    "output_file = \"20201208_approxf1_eval.json\"\n",
    "fp = \"/\".join([results_path, output_file])\n",
    "with open(fp, \"r+\") as f: \n",
    "    af1_results = json.load(f)\n",
    "    print(len(af1_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_taus = ['0.1', '0.125', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9']\n",
    "eval_taus = ['0.1', '0.2', '0.3', '0.4', '0.45', '0.5', '0.55', '0.6', '0.7', '0.8', '0.9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_runs(results_json): \n",
    "    '''Assuming each input is an array of JSONs that all have the same shape\n",
    "    This aggregates an array of jsons together into a singular one, based on the set fields below\n",
    "    '''\n",
    "    agg = {}\n",
    "    \n",
    "\n",
    "    # keep in mind that the evaluation distribution is evenly weighted. \n",
    "    eval_json = {}\n",
    "    taus = [0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.55, 0.6, 0.7, 0.8, 0.9]\n",
    "    for tau in taus: \n",
    "        eval_json[str(tau)] = {}\n",
    "        eval_json[str(tau)]['mean_f1'] =  np.mean([x['evaluation'][str(tau)]['mean_f1'] for x in results_json])\n",
    "        class_f1s = [x['evaluation'][str(tau)]['class_f1s'] for x in results_json]\n",
    "        eval_json[str(tau)]['class_f1s'] = np.mean(class_f1s, axis=0)\n",
    "    agg['eval'] = eval_json\n",
    "    \n",
    "\n",
    "    return agg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = float(len(results)) ## getting number of runs to divide by \n",
    "\n",
    "for run in runs:\n",
    "    # for each trained model \n",
    "    for train_tau in train_taus: \n",
    "        # for each eval threshold \n",
    "        for eval_tau in eval_taus:\n",
    "            \n",
    "            agg[train_tau][eval_tau]['mean_f1'] += run[train_tau][eval_tau]['mean_f1']  / num_runs\n",
    "            class_precisions = agg[train_tau][eval_tau]['class_precisions']\n",
    "            adj_prec = [x/num_runs for x in run[train_tau][eval_tau]['class_precisions']] \n",
    "            agg[train_tau][eval_tau]['class_precisions'] = np.add(\n",
    "                class_precisions, adj_prec)\n",
    "            \n",
    "            class_recalls = agg[train_tau][eval_tau]['class_recalls']\n",
    "            adj_rec = [x/num_runs for x in run[train_tau][eval_tau]['class_recalls']] \n",
    "            agg[train_tau][eval_tau]['class_recalls'] = np.add(\n",
    "                class_recalls, adj_rec)\n",
    "            \n",
    "            class_f1s = agg[train_tau][eval_tau]['class_f1s']\n",
    "            adj_f1s = [x/num_runs for x in run[train_tau][eval_tau]['class_f1s']] \n",
    "            agg[train_tau][eval_tau]['class_f1s'] = np.add(\n",
    "                class_f1s, adj_f1s)\n",
    "    run_counter += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4b832cb67fdb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maf1_agg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maf1_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-1abb9cb92d18>\u001b[0m in \u001b[0;36maggregate_runs\u001b[0;34m(results_json)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0magg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_json\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_wt_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_wt_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_json\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_wt_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_wt_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_json\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1abb9cb92d18>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0magg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'-'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_json\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_wt_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_wt_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_json\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_wt_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_wt_f1_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults_json\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "af1_agg = aggregate_runs(af1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_f1s': [0.7004607915878296,\n",
       "  0.6263735890388489,\n",
       "  0.48888882994651794,\n",
       "  0.4451826810836792,\n",
       "  0.5254236459732056,\n",
       "  0.5523011684417725,\n",
       "  0.6171427965164185,\n",
       "  0.6666666269302368,\n",
       "  0.770642101764679,\n",
       "  0.4755244553089142],\n",
       " 'class_precisions': [0.7169811129570007,\n",
       "  0.6129032373428345,\n",
       "  0.5057471394538879,\n",
       "  0.3366834223270416,\n",
       "  0.4492753744125366,\n",
       "  0.550000011920929,\n",
       "  0.6136363744735718,\n",
       "  0.6499999761581421,\n",
       "  0.800000011920929,\n",
       "  0.7555555701255798],\n",
       " 'class_recalls': [0.684684693813324,\n",
       "  0.6404494643211365,\n",
       "  0.47311827540397644,\n",
       "  0.656862735748291,\n",
       "  0.6326530575752258,\n",
       "  0.5546218752861023,\n",
       "  0.6206896305084229,\n",
       "  0.6842105388641357,\n",
       "  0.7433628439903259,\n",
       "  0.3469387888908386],\n",
       " 'mean_f1': 0.5868605971336365,\n",
       " 'eval_dxn': [4450, 4534, 4505, 4521, 4479, 4475, 4503, 4522, 4487, 4524]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]['0.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_f1s': [0.7004607915878296, 0.6263735890388489, 0.48888882994651794, 0.4451826810836792, 0.5254236459732056, 0.5523011684417725, 0.6171427965164185, 0.6666666269302368, 0.770642101764679, 0.4755244553089142], 'class_precisions': [0.7169811129570007, 0.6129032373428345, 0.5057471394538879, 0.3366834223270416, 0.4492753744125366, 0.550000011920929, 0.6136363744735718, 0.6499999761581421, 0.800000011920929, 0.7555555701255798], 'class_recalls': [0.684684693813324, 0.6404494643211365, 0.47311827540397644, 0.656862735748291, 0.6326530575752258, 0.5546218752861023, 0.6206896305084229, 0.6842105388641357, 0.7433628439903259, 0.3469387888908386], 'mean_f1': 0.5868605971336365, 'eval_dxn': [4450, 4534, 4505, 4521, 4479, 4475, 4503, 4522, 4487, 4524]}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0.1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2c560b3ff7aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_f1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_f1'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m/\u001b[0m \u001b[0mnum_runs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mclass_precisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_precisions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0madj_prec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnum_runs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meval_tau\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_precisions'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0.1'"
     ]
    }
   ],
   "source": [
    "num_runs = float(len(results)) ## getting number of runs to divide by \n",
    "\n",
    "for run in runs:\n",
    "    # for each trained model \n",
    "    for train_tau in train_taus: \n",
    "        # for each eval threshold \n",
    "        for eval_tau in eval_taus:\n",
    "            \n",
    "            agg[train_tau][eval_tau]['mean_f1'] += run[train_tau][eval_tau]['mean_f1']  / num_runs\n",
    "            class_precisions = agg[train_tau][eval_tau]['class_precisions']\n",
    "            adj_prec = [x/num_runs for x in run[train_tau][eval_tau]['class_precisions']] \n",
    "            agg[train_tau][eval_tau]['class_precisions'] = np.add(\n",
    "                class_precisions, adj_prec)\n",
    "            \n",
    "            class_recalls = agg[train_tau][eval_tau]['class_recalls']\n",
    "            adj_rec = [x/num_runs for x in run[train_tau][eval_tau]['class_recalls']] \n",
    "            agg[train_tau][eval_tau]['class_recalls'] = np.add(\n",
    "                class_recalls, adj_rec)\n",
    "            \n",
    "            class_f1s = agg[train_tau][eval_tau]['class_f1s']\n",
    "            adj_f1s = [x/num_runs for x in run[train_tau][eval_tau]['class_f1s']] \n",
    "            agg[train_tau][eval_tau]['class_f1s'] = np.add(\n",
    "                class_f1s, adj_f1s)\n",
    "    run_counter += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
