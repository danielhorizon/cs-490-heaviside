{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import tensorboard as tb\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall_time: 1605392097.8795836\n",
      "file_version: \"brain.Event:2\"\n",
      "\n",
      "wall_time: 1605392097.8858826\n",
      "summary {\n",
      "  value {\n",
      "    tag: \"loss\"\n",
      "    simple_value: 0.0\n",
      "  }\n",
      "}\n",
      "\n",
      "wall_time: 1605392097.8859286\n",
      "summary {\n",
      "  value {\n",
      "    tag: \"train/accuracy\"\n",
      "    simple_value: 0.0\n",
      "  }\n",
      "}\n",
      "\n",
      "wall_time: 1605392097.8859515\n",
      "summary {\n",
      "  value {\n",
      "    tag: \"train/w-f1\"\n",
      "    simple_value: 0.0\n",
      "  }\n",
      "}\n",
      "\n",
      "wall_time: 1605392097.8859723\n",
      "summary {\n",
      "  value {\n",
      "    tag: \"train/micro-f1\"\n",
      "    simple_value: 0.0\n",
      "  }\n",
      "}\n",
      "\n",
      "wall_time: 1605392097.8859923\n",
      "summary {\n",
      "  value {\n",
      "    tag: \"train/macro-f1\"\n",
      "    simple_value: 0.0\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/taesoodaniellee/Documents/heaviside/multiclass_src/tensorboard/baseline-ce-0/events.out.tfevents.1605392097.34dafb52bef4.8822.0\"\n",
    "counter = 0 \n",
    "for e in tf.compat.v1.train.summary_iterator(path):\n",
    "    if counter > 5: \n",
    "        break\n",
    "    print(e)\n",
    "    counter += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"baseline-ce-\"\n",
    "approx_f1 = \"approx-f1-regular-\"\n",
    "\n",
    "# imbalanced data \n",
    "baseline_imb = \"baseline-imb-\"\n",
    "approx_f1_imb = \"approx-f1-imb-\"\n",
    "\n",
    "# new approx \n",
    "new_approx = \"wt-approx-f1-imb-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/accuracy', 'test/micro-f1', 'test/macro-f1', 'test/w-f1', 'test/class-0-f1', 'test/class-0-precision', 'test/class-0-recall', 'test/class-0-TP', 'test/class-0-FP', 'test/class-0-FN', 'test/class-0-TN', 'test/class-1-f1', 'test/class-1-precision', 'test/class-1-recall', 'test/class-1-TP', 'test/class-1-FP', 'test/class-1-FN', 'test/class-1-TN', 'test/class-2-f1', 'test/class-2-precision', 'test/class-2-recall', 'test/class-2-TP', 'test/class-2-FP', 'test/class-2-FN', 'test/class-2-TN', 'test/class-3-f1', 'test/class-3-precision', 'test/class-3-recall', 'test/class-3-TP', 'test/class-3-FP', 'test/class-3-FN', 'test/class-3-TN', 'test/class-4-f1', 'test/class-4-precision', 'test/class-4-recall', 'test/class-4-TP', 'test/class-4-FP', 'test/class-4-FN', 'test/class-4-TN', 'test/class-5-f1', 'test/class-5-precision', 'test/class-5-recall', 'test/class-5-TP', 'test/class-5-FP', 'test/class-5-FN', 'test/class-5-TN', 'test/class-6-f1', 'test/class-6-precision', 'test/class-6-recall', 'test/class-6-TP', 'test/class-6-FP', 'test/class-6-FN', 'test/class-6-TN', 'test/class-7-f1', 'test/class-7-precision', 'test/class-7-recall', 'test/class-7-TP', 'test/class-7-FP', 'test/class-7-FN', 'test/class-7-TN', 'test/class-8-f1', 'test/class-8-precision', 'test/class-8-recall', 'test/class-8-TP', 'test/class-8-FP', 'test/class-8-FN', 'test/class-8-TN', 'test/class-9-f1', 'test/class-9-precision', 'test/class-9-recall', 'test/class-9-TP', 'test/class-9-FP', 'test/class-9-FN', 'test/class-9-TN']\n"
     ]
    }
   ],
   "source": [
    "test_tags = ['test/accuracy', 'test/micro-f1', 'test/macro-f1', 'test/w-f1']\n",
    "for i in range(10):\n",
    "    f1 = \"test/class-\" + str(i) + \"-f1\"\n",
    "    precision = \"test/class-\" + str(i) + \"-precision\"\n",
    "    recall = \"test/class-\" + str(i) + \"-recall\"\n",
    "    tp = \"test/class-\" + str(i) + \"-TP\"\n",
    "    fp = \"test/class-\" + str(i) + \"-FP\"\n",
    "    fn = \"test/class-\" + str(i) + \"-FN\"\n",
    "    tn = \"test/class-\" + str(i) + \"-TN\"\n",
    "    test_tags.extend([f1, precision, recall, tp, fp, fn, tn])\n",
    "print(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'train/accuracy', 'train/w-f1', 'train/micro-f1', 'train/macro-f1', 'train/w-recalltrain/micro-recall', 'train/macro-recall', 'train/w-precision', 'train/micro-precision', 'train/macro-precision', 'train/class-0-f1', 'train/class-0-precision', 'train/class-0-recall', 'train/class-1-f1', 'train/class-1-precision', 'train/class-1-recall', 'train/class-2-f1', 'train/class-2-precision', 'train/class-2-recall', 'train/class-3-f1', 'train/class-3-precision', 'train/class-3-recall', 'train/class-4-f1', 'train/class-4-precision', 'train/class-4-recall', 'train/class-5-f1', 'train/class-5-precision', 'train/class-5-recall', 'train/class-6-f1', 'train/class-6-precision', 'train/class-6-recall', 'train/class-7-f1', 'train/class-7-precision', 'train/class-7-recall', 'train/class-8-f1', 'train/class-8-precision', 'train/class-8-recall', 'train/class-9-f1', 'train/class-9-precision', 'train/class-9-recall']\n"
     ]
    }
   ],
   "source": [
    "train_tags = ['loss', 'train/accuracy', 'train/w-f1', 'train/micro-f1', 'train/macro-f1', 'train/w-recall'\\\n",
    "             'train/micro-recall', 'train/macro-recall', 'train/w-precision', 'train/micro-precision', \\\n",
    "             'train/macro-precision']\n",
    "for i in range(10): \n",
    "    f1 = \"train/class-\" + str(i) + \"-f1\"\n",
    "    precision = \"train/class-\"+ str(i) + \"-precision\"\n",
    "    recall = \"train/class-\" + str(i) + \"-recall\"\n",
    "    train_tags.extend([f1, precision, recall])\n",
    "print(train_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_valid_tags = ['val/accuracy', 'val/micro-f1', 'val/macro-f1', 'val/w-f1']\n",
    "for i in range(10): \n",
    "    f1 = \"val/class-\" + str(i) + \"-f1\"\n",
    "    precision = \"val/class-\" + str(i) + \"-precision\"\n",
    "    recall = \"val/class-\" + str(i) + \"-recall\"\n",
    "    tp = \"val/class-\" + str(i) + \"-TP\"\n",
    "    fp = \"val/class-\" + str(i) + \"-FP\"\n",
    "    fn = \"val/class-\" + str(i) + \"-FN\"\n",
    "    tn = \"val/class-\" + str(i) + \"-TN\"\n",
    "    baseline_valid_tags.extend([f1, precision, recall, tp, fp, fn, tn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val/accuracy', 'val/micro-f1', 'val/macro-f1', 'val/w-f1', 'val/class-0-f1', 'val/class-0-precision', 'val/class-0-recall', 'val/class-0-TP', 'val/class-0-FP', 'val/class-0-FN', 'val/class-0-TN', 'val/class-1-f1', 'val/class-1-precision', 'val/class-1-recall', 'val/class-1-TP', 'val/class-1-FP', 'val/class-1-FN', 'val/class-1-TN', 'val/class-2-f1', 'val/class-2-precision', 'val/class-2-recall', 'val/class-2-TP', 'val/class-2-FP', 'val/class-2-FN', 'val/class-2-TN', 'val/class-3-f1', 'val/class-3-precision', 'val/class-3-recall', 'val/class-3-TP', 'val/class-3-FP', 'val/class-3-FN', 'val/class-3-TN', 'val/class-4-f1', 'val/class-4-precision', 'val/class-4-recall', 'val/class-4-TP', 'val/class-4-FP', 'val/class-4-FN', 'val/class-4-TN', 'val/class-5-f1', 'val/class-5-precision', 'val/class-5-recall', 'val/class-5-TP', 'val/class-5-FP', 'val/class-5-FN', 'val/class-5-TN', 'val/class-6-f1', 'val/class-6-precision', 'val/class-6-recall', 'val/class-6-TP', 'val/class-6-FP', 'val/class-6-FN', 'val/class-6-TN', 'val/class-7-f1', 'val/class-7-precision', 'val/class-7-recall', 'val/class-7-TP', 'val/class-7-FP', 'val/class-7-FN', 'val/class-7-TN', 'val/class-8-f1', 'val/class-8-precision', 'val/class-8-recall', 'val/class-8-TP', 'val/class-8-FP', 'val/class-8-FN', 'val/class-8-TN', 'val/class-9-f1', 'val/class-9-precision', 'val/class-9-recall', 'val/class-9-TP', 'val/class-9-FP', 'val/class-9-FN', 'val/class-9-TN']\n"
     ]
    }
   ],
   "source": [
    "print(baseline_valid_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tags = ['val/accuracy', 'val/micro-f1', 'val/macro-f1', 'val/w-f1']\n",
    "for i in range(10): \n",
    "    f1 = \"val/class-\" + str(i) + \"-f1\"\n",
    "    precision = \"val/class-\" + str(i) + \"-precision\"\n",
    "    recall = \"val/class-\" + str(i) + \"-recall\"\n",
    "    tp = \"val/class-\" + str(i) + \"-TP\"\n",
    "    fp = \"val/class-\" + str(i) + \"-FP\"\n",
    "    fn = \"val/class-\" + str(i) + \"-FN\"\n",
    "    tn = \"val/class-\" + str(i) + \"-TN\"\n",
    "    ss_tp = \"val/class-\" + str(i) + \"-softset-\" + \"TP\"\n",
    "    ss_fp = \"val/class-\" + str(i) + \"-softset-\" + \"FP\"\n",
    "    ss_fn = \"val/class-\" + str(i) + \"-softset-\" + \"FN\"\n",
    "    ss_tn = \"val/class-\" + str(i) + \"-softset-\" + \"TN\"\n",
    "    valid_tags.extend([f1, precision, recall, tp, fp, fn, tn, ss_tp, ss_fp, ss_fn, ss_tn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['val/accuracy', 'val/micro-f1', 'val/macro-f1', 'val/w-f1', ['val/class-0-f1', 'val/class-0-precision', 'val/class-0-recall', 'val/class-0-TP', 'val/class-0-FP', 'val/class-0-FN', 'val/class-0-TN'], ['val/class-1-f1', 'val/class-1-precision', 'val/class-1-recall', 'val/class-1-TP', 'val/class-1-FP', 'val/class-1-FN', 'val/class-1-TN'], ['val/class-2-f1', 'val/class-2-precision', 'val/class-2-recall', 'val/class-2-TP', 'val/class-2-FP', 'val/class-2-FN', 'val/class-2-TN'], ['val/class-3-f1', 'val/class-3-precision', 'val/class-3-recall', 'val/class-3-TP', 'val/class-3-FP', 'val/class-3-FN', 'val/class-3-TN'], ['val/class-4-f1', 'val/class-4-precision', 'val/class-4-recall', 'val/class-4-TP', 'val/class-4-FP', 'val/class-4-FN', 'val/class-4-TN'], ['val/class-5-f1', 'val/class-5-precision', 'val/class-5-recall', 'val/class-5-TP', 'val/class-5-FP', 'val/class-5-FN', 'val/class-5-TN'], ['val/class-6-f1', 'val/class-6-precision', 'val/class-6-recall', 'val/class-6-TP', 'val/class-6-FP', 'val/class-6-FN', 'val/class-6-TN'], ['val/class-7-f1', 'val/class-7-precision', 'val/class-7-recall', 'val/class-7-TP', 'val/class-7-FP', 'val/class-7-FN', 'val/class-7-TN'], ['val/class-8-f1', 'val/class-8-precision', 'val/class-8-recall', 'val/class-8-TP', 'val/class-8-FP', 'val/class-8-FN', 'val/class-8-TN'], ['val/class-9-f1', 'val/class-9-precision', 'val/class-9-recall', 'val/class-9-TP', 'val/class-9-FP', 'val/class-9-FN', 'val/class-9-TN']]\n"
     ]
    }
   ],
   "source": [
    "print(baseline_valid_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tbparser.summary_reader import SummaryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved for class 0...\n",
      "saved for class 1...\n",
      "saved for class 2...\n",
      "saved for class 3...\n",
      "saved for class 4...\n",
      "saved for class 5...\n",
      "saved for class 6...\n",
      "saved for class 7...\n",
      "saved for class 8...\n",
      "saved for class 9...\n",
      "                        tag  epoch         value       run_name       stage\n",
      "0              val/accuracy      0      0.084800  baseline-ce-0  validation\n",
      "1              val/micro-f1      0      0.084800  baseline-ce-0  validation\n",
      "2              val/macro-f1      0      0.039067  baseline-ce-0  validation\n",
      "3                  val/w-f1      0      0.039435  baseline-ce-0  validation\n",
      "4            val/class-0-f1      0      0.108503  baseline-ce-0  validation\n",
      "...                     ...    ...           ...            ...         ...\n",
      "269575  test/class-9-recall    143      0.787400  baseline-ce-9        test\n",
      "269576      test/class-9-TP    143   3937.000000  baseline-ce-9        test\n",
      "269577      test/class-9-FP    143    749.000000  baseline-ce-9        test\n",
      "269578      test/class-9-FN    143   1063.000000  baseline-ce-9        test\n",
      "269579      test/class-9-TN    143  33834.000000  baseline-ce-9        test\n",
      "\n",
      "[269580 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "baseline_results = []\n",
    "for i in range(10): \n",
    "    # extracting the baseline results\n",
    "    logdir = '/Users/taesoodaniellee/Documents/heaviside/multiclass_src/tensorboard/baseline-ce-' + str(i)\n",
    "    \n",
    "    # extract the validation results \n",
    "    # [tag, step, value, run_name]\n",
    "    reader = SummaryReader(logdir, tag_filter=baseline_valid_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"baseline-ce-\"+str(i), \"validation\"]\n",
    "        baseline_results.append(datapoint)\n",
    "    \n",
    "    # extract the train results \n",
    "    reader = SummaryReader(logdir, tag_filter=train_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"baseline-ce-\"+str(i), \"train\"]\n",
    "        baseline_results.append(datapoint)\n",
    "        \n",
    "    # extract the test results \n",
    "    reader = SummaryReader(logdir, tag_filter=test_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"baseline-ce-\"+str(i), \"test\"]\n",
    "        baseline_results.append(datapoint)\n",
    "    print(\"saved for class {}...\".format(str(i)))\n",
    "baseline_df = pd.DataFrame(baseline_results, columns=['tag', 'epoch', 'value', 'run_name', 'stage'])\n",
    "print(baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved for class 0...\n",
      "saved for class 1...\n",
      "saved for class 2...\n",
      "saved for class 3...\n",
      "saved for class 4...\n",
      "saved for class 5...\n",
      "saved for class 6...\n",
      "saved for class 7...\n",
      "saved for class 8...\n",
      "saved for class 9...\n",
      "                        tag  epoch        value        run_name       stage\n",
      "0              val/accuracy      0     0.086000  baseline-imb-0  validation\n",
      "1              val/micro-f1      0     0.086000  baseline-imb-0  validation\n",
      "2              val/macro-f1      0     0.035099  baseline-imb-0  validation\n",
      "3                  val/w-f1      0     0.035078  baseline-imb-0  validation\n",
      "4            val/class-0-f1      0     0.000000  baseline-imb-0  validation\n",
      "...                     ...    ...          ...             ...         ...\n",
      "256746  test/class-9-recall    171     0.268000  baseline-imb-9        test\n",
      "256747      test/class-9-TP    171   268.000000  baseline-imb-9        test\n",
      "256748      test/class-9-FP    171   218.000000  baseline-imb-9        test\n",
      "256749      test/class-9-FN    171   732.000000  baseline-imb-9        test\n",
      "256750      test/class-9-TN    171  4051.000000  baseline-imb-9        test\n",
      "\n",
      "[256751 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "baseline_imb_results = []\n",
    "for i in range(10): \n",
    "    # extracting the baseline results\n",
    "    logdir = '/Users/taesoodaniellee/Documents/heaviside/multiclass_src/tensorboard/baseline-imb-' + str(i)\n",
    "    \n",
    "    # extract the validation results \n",
    "    # [tag, step, value, run_name]\n",
    "    reader = SummaryReader(logdir, tag_filter=baseline_valid_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"baseline-imb-\"+str(i), \"validation\"]\n",
    "        baseline_imb_results.append(datapoint)\n",
    "    \n",
    "    # extract the train results \n",
    "    reader = SummaryReader(logdir, tag_filter=train_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"baseline-imb-\"+str(i), \"train\"]\n",
    "        baseline_imb_results.append(datapoint)\n",
    "        \n",
    "    # extract the test results \n",
    "    reader = SummaryReader(logdir, tag_filter=test_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"baseline-imb-\"+str(i), \"test\"]\n",
    "        baseline_imb_results.append(datapoint)\n",
    "    print(\"saved for class {}...\".format(str(i)))\n",
    "baseline_imb_df = pd.DataFrame(baseline_imb_results, columns=['tag', 'epoch', 'value', 'run_name', 'stage'])\n",
    "print(baseline_imb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved for class 0...\n",
      "saved for class 1...\n",
      "saved for class 2...\n",
      "saved for class 3...\n",
      "saved for class 4...\n",
      "saved for class 5...\n",
      "saved for class 6...\n",
      "saved for class 7...\n",
      "saved for class 8...\n",
      "saved for class 9...\n",
      "                        tag  epoch         value             run_name  \\\n",
      "0              val/accuracy      0      0.084800  approx-f1-regular-0   \n",
      "1              val/micro-f1      0      0.084800  approx-f1-regular-0   \n",
      "2              val/macro-f1      0      0.039067  approx-f1-regular-0   \n",
      "3                  val/w-f1      0      0.039435  approx-f1-regular-0   \n",
      "4            val/class-0-f1      0      0.108503  approx-f1-regular-0   \n",
      "...                     ...    ...           ...                  ...   \n",
      "345627  test/class-9-recall    153      0.781600  approx-f1-regular-9   \n",
      "345628      test/class-9-TP    153   3908.000000  approx-f1-regular-9   \n",
      "345629      test/class-9-FP    153   1479.000000  approx-f1-regular-9   \n",
      "345630      test/class-9-FN    153   1092.000000  approx-f1-regular-9   \n",
      "345631      test/class-9-TN    153  30750.000000  approx-f1-regular-9   \n",
      "\n",
      "             stage  \n",
      "0       validation  \n",
      "1       validation  \n",
      "2       validation  \n",
      "3       validation  \n",
      "4       validation  \n",
      "...            ...  \n",
      "345627        test  \n",
      "345628        test  \n",
      "345629        test  \n",
      "345630        test  \n",
      "345631        test  \n",
      "\n",
      "[345632 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "approx_f1_reg = []\n",
    "for i in range(10): \n",
    "    # extracting the baseline results\n",
    "    logdir = '/Users/taesoodaniellee/Documents/heaviside/multiclass_src/tensorboard/approx-f1-regular-' + str(i)\n",
    "    \n",
    "    # extract the validation results \n",
    "    # [tag, step, value, run_name]\n",
    "    reader = SummaryReader(logdir, tag_filter=valid_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"approx-f1-regular-\"+str(i), \"validation\"]\n",
    "        approx_f1_reg.append(datapoint)\n",
    "    \n",
    "    # extract the train results \n",
    "    reader = SummaryReader(logdir, tag_filter=train_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"approx-f1-regular-\"+str(i), \"train\"]\n",
    "        approx_f1_reg.append(datapoint)\n",
    "        \n",
    "    # extract the test results \n",
    "    reader = SummaryReader(logdir, tag_filter=test_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"approx-f1-regular-\"+str(i), \"test\"]\n",
    "        approx_f1_reg.append(datapoint)\n",
    "    print(\"saved for class {}...\".format(str(i)))\n",
    "    \n",
    "approx_f1_reg_df = pd.DataFrame(approx_f1_reg, columns=['tag', 'epoch', 'value', 'run_name', 'stage'])\n",
    "print(approx_f1_reg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved for class 0...\n",
      "saved for class 1...\n",
      "saved for class 2...\n",
      "saved for class 3...\n",
      "saved for class 4...\n",
      "saved for class 5...\n",
      "saved for class 6...\n",
      "saved for class 7...\n",
      "saved for class 8...\n",
      "saved for class 9...\n",
      "                        tag  epoch        value         run_name       stage\n",
      "0              val/accuracy      0     0.086000  approx-f1-imb-0  validation\n",
      "1              val/micro-f1      0     0.086000  approx-f1-imb-0  validation\n",
      "2              val/macro-f1      0     0.035099  approx-f1-imb-0  validation\n",
      "3                  val/w-f1      0     0.035078  approx-f1-imb-0  validation\n",
      "4            val/class-0-f1      0     0.000000  approx-f1-imb-0  validation\n",
      "...                     ...    ...          ...              ...         ...\n",
      "259386  test/class-9-recall     86     0.342000  approx-f1-imb-9        test\n",
      "259387      test/class-9-TP     86   342.000000  approx-f1-imb-9        test\n",
      "259388      test/class-9-FP     86   255.000000  approx-f1-imb-9        test\n",
      "259389      test/class-9-FN     86   658.000000  approx-f1-imb-9        test\n",
      "259390      test/class-9-TN     86  3909.000000  approx-f1-imb-9        test\n",
      "\n",
      "[259391 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "approx_f1_imb = []\n",
    "for i in range(10): \n",
    "    # extracting the baseline results\n",
    "    logdir = '/Users/taesoodaniellee/Documents/heaviside/multiclass_src/tensorboard/approx-f1-imb-' + str(i)\n",
    "    \n",
    "    # extract the validation results \n",
    "    # [tag, step, value, run_name]\n",
    "    reader = SummaryReader(logdir, tag_filter=valid_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"approx-f1-imb-\"+str(i), \"validation\"]\n",
    "        approx_f1_imb.append(datapoint)\n",
    "    \n",
    "    # extract the train results \n",
    "    reader = SummaryReader(logdir, tag_filter=train_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"approx-f1-imb-\"+str(i), \"train\"]\n",
    "        approx_f1_imb.append(datapoint)\n",
    "        \n",
    "    # extract the test results \n",
    "    reader = SummaryReader(logdir, tag_filter=test_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"approx-f1-imb-\"+str(i), \"test\"]\n",
    "        approx_f1_imb.append(datapoint)\n",
    "    print(\"saved for class {}...\".format(str(i)))\n",
    "    \n",
    "approx_f1_imb_df = pd.DataFrame(approx_f1_imb, columns=['tag', 'epoch', 'value', 'run_name', 'stage'])\n",
    "print(approx_f1_imb_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved for class 0...\n",
      "saved for class 1...\n",
      "saved for class 2...\n",
      "saved for class 3...\n",
      "saved for class 4...\n",
      "saved for class 5...\n",
      "saved for class 6...\n",
      "saved for class 7...\n",
      "saved for class 8...\n",
      "saved for class 9...\n",
      "                        tag  epoch        value            run_name  \\\n",
      "0              val/accuracy      0     0.086000  wt-approx-f1-imb-0   \n",
      "1              val/micro-f1      0     0.086000  wt-approx-f1-imb-0   \n",
      "2              val/macro-f1      0     0.035099  wt-approx-f1-imb-0   \n",
      "3                  val/w-f1      0     0.035078  wt-approx-f1-imb-0   \n",
      "4            val/class-0-f1      0     0.000000  wt-approx-f1-imb-0   \n",
      "...                     ...    ...          ...                 ...   \n",
      "359511  test/class-9-recall     96     0.179000  wt-approx-f1-imb-9   \n",
      "359512      test/class-9-TP     96   179.000000  wt-approx-f1-imb-9   \n",
      "359513      test/class-9-FP     96   118.000000  wt-approx-f1-imb-9   \n",
      "359514      test/class-9-FN     96   821.000000  wt-approx-f1-imb-9   \n",
      "359515      test/class-9-TN     96  2287.000000  wt-approx-f1-imb-9   \n",
      "\n",
      "             stage  \n",
      "0       validation  \n",
      "1       validation  \n",
      "2       validation  \n",
      "3       validation  \n",
      "4       validation  \n",
      "...            ...  \n",
      "359511        test  \n",
      "359512        test  \n",
      "359513        test  \n",
      "359514        test  \n",
      "359515        test  \n",
      "\n",
      "[359516 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "wt_approx_f1_imb = []\n",
    "for i in range(10): \n",
    "    # extracting the baseline results\n",
    "    logdir = '/Users/taesoodaniellee/Documents/heaviside/multiclass_src/tensorboard/wt-approx-f1-imb-' + str(i)\n",
    "    \n",
    "    # extract the validation results \n",
    "    # [tag, step, value, run_name]\n",
    "    reader = SummaryReader(logdir, tag_filter=valid_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"wt-approx-f1-imb-\"+str(i), \"validation\"]\n",
    "        wt_approx_f1_imb.append(datapoint)\n",
    "    \n",
    "    # extract the train results \n",
    "    reader = SummaryReader(logdir, tag_filter=train_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"wt-approx-f1-imb-\"+str(i), \"train\"]\n",
    "        wt_approx_f1_imb.append(datapoint)\n",
    "        \n",
    "    # extract the test results \n",
    "    reader = SummaryReader(logdir, tag_filter=test_tags)\n",
    "    for item in reader: \n",
    "        datapoint = [item[0], item[1], item[3], \"wt-approx-f1-imb-\"+str(i), \"test\"]\n",
    "        wt_approx_f1_imb.append(datapoint)\n",
    "    print(\"saved for class {}...\".format(str(i)))\n",
    "    \n",
    "wt_approx_f1_imb_df = pd.DataFrame(wt_approx_f1_imb, columns=['tag', 'epoch', 'value', 'run_name', 'stage'])\n",
    "print(wt_approx_f1_imb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269580, 5)\n",
      "(256751, 5)\n",
      "(345632, 5)\n",
      "(259391, 5)\n",
      "(359516, 5)\n"
     ]
    }
   ],
   "source": [
    "print(baseline_df.shape)\n",
    "print(baseline_imb_df.shape)\n",
    "print(approx_f1_reg_df.shape)\n",
    "print(approx_f1_imb_df.shape)\n",
    "print(wt_approx_f1_imb_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train \n",
    "# for validation \n",
    "# for test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
